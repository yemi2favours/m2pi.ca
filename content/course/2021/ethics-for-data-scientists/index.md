---
title: "Ethics for Data Scientists"
authors: [lgf]

summary: | 
  Participants will explore some of the pitfalls of artificial intelligence when
  it is used to make decisisons which will impacting people and also how to
  design ethical models.


tags: ['2021']
categories: []
date: 2021-07-25T16:58:18-07:00

external_link: ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---

### Description
In recent years we have seen a rise in the use of artificial intelligence in our
everyday lives: from machine learning algorithms that screen resumes for job
postings, to bots that can converse with one another. In this workshop,
participants will explore the pitfalls of artificial intelligence when it comes
to algorithms responsible for making decisions impacting lives, and what our
responsibilities are to ensure our models are ethical.

### Learning outcomes

By the end of this session, participants will be familiar with

 * An overview of different frameworks data scientists use when modelling or
   abstracting.
 * Various types of pitfalls data scientists can fall into when modelling or
   abstracting a problem using machine learning techniques.
 * Concrete examples of what these pitfalls look like in practice, with a focus
   on consequences on parties affected by algorithms.
 * An introduction to Fairlearn: a Python-based library that helps data
   scientists improve fairness in machine learning and artificial intelligence
   systems.
